## /etc/logcheck/ignore.d.server/local-rules
## Ubuntu 14.04
kernel: \[[. [:digit:]]*\] perf samples too long ([[:digit:]]* > [0-9]*), lowering kernel.perf_event_max_sample_rate to [[:digit:]]*$
ntpd\[[0-9]+\]: adjusting clock frequency by [0-9]+\.[0-9]+ to [0-9]+\.[0-9]+ppm
ntpd\[[0-9]+\]: adjusting clock frequency by [0-9]+\.[0-9]+ to -[0-9]+\.[0-9]+ppm
ntpd\[[0-9]+\]: adjusting clock frequency by -[0-9]+\.[0-9]+ to [0-9]+\.[0-9]+ppm
ntpd\[[0-9]+\]: adjusting clock frequency by -[0-9]+\.[0-9]+ to -[0-9]+\.[0-9]+ppm
ntpd\[[0-9]+\]: adjusting local clock by [-]*[0-9]+\.[0-9]+s
ntpd\[[0-9]+\]: bad peer from pool [0-9]+.debian.pool.ntp.org
ntpd\[[0-9]+\]: [0-9]+ out of [0-9]+ peers valid
ntpd\[[0-9]+\]: reply from [\.0-9]+: not synced, next query [0-9]+s
auditd\[[0-9]+\]: Audit daemon rotating log files

kernel\[[0-9]+\]: \[[0-9N]+\.[0-9N]+\] INFO: NMI handler (perf_event_nmi_handler) took too long to run: [0-9]+\.[0-9]+ msecs
kernel: \[[. [:digit:]]+\] hrtimer: interrupt took [[:digit:]]+ ns$
## oom killer
kernel: \[[0-9N]*\.[0-9N]*\] \[[0-9 ]*\]\s*[0-9]*\s*[0-9]*\s*[0-9]*\s*[0-9]*\s*[0-9]*\s*[0-9]*\s*[0-9]*\s*[0-9]*\s*.*
kernel: \[[0-9N]*\.[0-9N]*\] Node [0-9]+ hugepages_total=[0-9]+ hugepages_free=[0-9]+ hugepages_surp=[0-9]+ hugepages_size=[0-9]+kB
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ total pagecache pages
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ pages in swap cache
kernel: \[[0-9N]*\.[0-9N]*\] Swap cache stats: add [0-9]+, delete [0-9]+, find [0-9]+\/[0-9]+
kernel: \[[0-9N]*\.[0-9N]*\] Free swap  = [0-9]+kB
kernel: \[[0-9N]*\.[0-9N]*\] Total swap = [0-9]+kB
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ pages RAM
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ pages HighMem\/MovableOnly
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ pages reserved
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ pages cma reserved
kernel: \[[0-9N]*\.[0-9N]*\] [0-9]+ pages hwpoisoned
kernel: \[ [0-9N]*\.[0-9N]*\] acpiphp: Slot \[[0-9]+\] registered

rrdcached\[[0-9]+\]: flushing old values
rrdcached\[[0-9]+\]: removing old journal /var/cache/rrdcached/rrd.journal.[0-9]+\.[0-9]+
rrdcached\[[0-9]+\]: rotating journals
rrdcached\[[0-9]+\]: started new journal /var/cache/rrdcached/rrd.journal.[0-9]+\.[0-9]+
systemd-logind\[[0-9]+\]: New session c[0-9]+ of user nobody.
systemd-logind\[[0-9]+\]: New session [0-9]+ of user vagrant.
systemd-logind\[[0-9]+\]: Removed session [0-9]+.
systemd-logind\[[0-9]+\]: Removed session c[0-9]+.
## suppress issues that arise with publicly available services that people try to exploit. https://gist.github.com/towo/9600375
sshd\[[[:digit:]]+\]: Did not receive identification string from ::ffff:[\.0-9]+$
sshd\[[[:digit:]]+\]: fatal: Read from socket failed: Connection reset by peer \[preauth\]$
#^\w{3} [ :[:digit:]]{11} [._[:alnum:]-]+ sshd\[[[:digit:]]+\]: I(llegal|nvalid) user [^[:space:]]* from ([:.[:xdigit:]]+|UNKNOWN)$
sshd\[[[:digit:]]+\]: invalid public DH value: <= 1 \[preauth\]$
sshd\[[[:digit:]]+\]: Disconnecting: bad client public DH value \[preauth\]$
sshd\[[[:digit:]]+\]: Disconnecting: Change of username or service not allowed: \([[:alpha:]]+,ssh-connection\) -> \([[:alpha:]]+,ssh-connection\) \[preauth\]$
#sshd\[[[:digit:]]+\]: Received disconnect from [:.[:xdigit:]]+: 3: com.jcraft.jsch.JSchException: Auth fail \[preauth\]$
sshd\[[[:digit:]]+\]: error: Received disconnect from [:.[:xdigit:]]+: 3: com.jcraft.jsch.JSchException: Auth fail \[preauth\]$
sshd\[[[:digit:]]+\]: Received disconnect from [\.0-9]+: 11: Bye Bye \[preauth\]$
sshd\[[[:digit:]]+\]: Received disconnect from [:.[:xdigit:]]+: 11: Goodbye \[preauth\]$
sshd\[[[:digit:]]+\]: Received disconnect from [:.[:xdigit:]]+: 11: PECL/ssh2 \(http://pecl.php.net/packages/ssh2\) \[preauth\]$
sshd\[[0-9]*\]: fatal: Unable to negotiate with \([0-9a-fA-F\.:]*\) port [0-9]*: no matching
sshd\[[0-9]*\]: Connection from \([0-9a-fA-F\.:]*\) port [0-9]* on \([0-9\.:]*\) port \([0-9]*\)
sshd\[[0-9]*\]: User child is on pid [0-9]*
##
##dhclient\[[[:digit:]]+\]: DHCPREQUEST of [\.0-9]+ on eth0 to [\.0-9]+ port [0-9]+ (xid=0x[0-9a-f]+)
#dhclient\[[0-9]+\]: DHCPREQUEST of [\.0-9]+ on eth0 to [\.0-9]+ port [0-9]+ (xid=0x[0-9a-f]+)
## Ubuntu 16.04
systemd\[[0-9]+\]: Started LSB: process and login accounting.
systemd\[[0-9]+\]: Starting LSB: process and login accounting...
systemd\[[0-9]+\]: Stopped LSB: process and login accounting.
systemd\[[0-9]+\]: Stopping LSB: process and login accounting...
acct\[[0-9]+\]:  \* Done.
systemd\[[0-9]+\]: Starting Automatically refresh installed snaps...
systemd\[[0-9]+\]: snapd.refresh.timer: Adding [0-9]+h [0-9]+min [0-9]+\.[0-9]+s random time.
systemd\[[0-9]+\]: snapd.refresh.timer: Adding [0-9]+min [0-9]+\.[0-9]+s random time.
systemd\[[0-9]+\]: Started Automatically refresh installed snaps.
systemd\[[0-9]+\]: Started Cleanup of Temporary Directories.
systemd\[[0-9]+\]: Starting Cleanup of Temporary Directories...
systemd\[[0-9]+\]: Starting Daily apt activities...
systemd\[[0-9]+\]: Started Daily apt activities.
systemd\[[0-9]+\]: apt-daily.timer: Adding [0-9]+h [0-9]+min [0-9]+\.[0-9]+s random time.
systemd\[[0-9]+\]: apt-daily.timer: Adding [0-9]+min [0-9]+\.[0-9]+s random time.
systemd\[[0-9]+\]: Created slice User Slice of root.
systemd\[[0-9]+\]: Removed slice User Slice of root.
systemd\[[0-9]+\]: Started Session N of user root.
systemd\[[0-9]+\]: Started User Manager for UID 0.
systemd\[[0-9]+\]: Starting User Manager for UID 0...
systemd\[[0-9]+\]: Starting .*\.\.\.
systemd\[[0-9]+\]: Stopped User Manager for UID 0.
systemd\[[0-9]+\]: Stopping User Manager for UID 0...
systemd\[[0-9]+\]: Stopping .*\.\.\.
systemd\[[0-9]+\]: Reached target Basic System.
systemd\[[0-9]+\]: Reached target Default.
systemd\[[0-9]+\]: Reached target Paths.
systemd\[[0-9]+\]: Reached target Sockets.
systemd\[[0-9]+\]: Reached target Timers.
systemd\[[0-9]+\]: Reached target Shutdown.
systemd\[[0-9]+\]: Startup finished in [0-9]+ms.
systemd\[[0-9]+\]: Starting Exit the Session...
systemd\[[0-9]+\]: Stopped target Basic System.
systemd\[[0-9]+\]: Stopped target Default.
systemd\[[0-9]+\]: Stopped target Paths.
systemd\[[0-9]+\]: Stopped target Sockets.
systemd\[[0-9]+\]: Stopped target Timers.
snap\[[0-9]+\]: \#015\#033\[K
snap\[[0-9]+\]: All snaps up to date.
\/usr\/lib\/snapd\/snapd\[[0-9]*\]: daemon.go:[0-9]*: DEBUG: uid=[0-9]*;@ POST \/v2\/snaps [0-9]*\.[0-9]*s [0-9]*
\/usr\/lib\/snapd\/snapd\[[0-9]*\]: daemon.go:[0-9]*: DEBUG: uid=[0-9]*;@ POST \/v2\/snaps [0-9]*\.[0-9]*ms [0-9]*
\/usr\/lib\/snapd\/snapd: daemon.go:209: DEBUG: init done in [0-9]*\.[0-9]*ms
\/usr\/lib\/snapd\/snapd: daemon.go:219: DEBUG: adding \/.*

## verbose sshd
sshd\[[0-9]+\]: Set /proc/self/oom_score_adj to 0
sshd\[[0-9]+\]: Set /proc/self/oom_score_adj from [0-9]* to [0-9]*

### nrpe
nagios-nrpe-server\[[0-9]+\]:    ...done.
nagios-nrpe-server\[[0-9]+\]:  * Stopping nagios-nrpe nagios-nrpe
nagios-nrpe-server\[[0-9]+\]:  * Starting nagios-nrpe nagios-nrpe
nrpe\[[0-9]+\]: Caught SIGTERM - shutting down...
nrpe\[[0-9]+\]: Daemon shutdown
nrpe\[[0-9]+\]: Allowing connections from: 127.0.0.1
nrpe\[[0-9]+\]: Listening for connections on port 0
nrpe\[[0-9]+\]: Server listening on 0.0.0.0 port 5666.
nrpe\[[0-9]+\]: Server listening on :: port 5666.
nrpe\[[0-9]+\]: Starting up daemon
#systemd\[[0-9]+\]: Started LSB: Start/Stop the Nagios remote plugin execution daemon.
systemd\[[0-9]+\]: Starting LSB: Start/Stop the Nagios remote plugin execution daemon...
#systemd\[[0-9]+\]: Stopped LSB: Start/Stop the Nagios remote plugin execution daemon.
systemd\[[0-9]+\]: Stopping LSB: Start/Stop the Nagios remote plugin execution daemon...

## osquery
osqueryd\[[0-9]*\]: .* [0-9]*:[0-9]*:[0-9]*\.[0-9]*\s*[0-9]* scheduler.cpp:63\] Executing scheduled query: pack_.*
osqueryd\[[0-9]*\]: .* [0-9]*:[0-9]*:[0-9]*\.[0-9]*\s*[0-9]* scheduler.cpp:63\] Executing scheduled query: system_info.*
osqueryd\[[0-9]*\]: .* [0-9]*:[0-9]*:[0-9]*\.[0-9]*\s*[0-9]* rocksdb.cpp:191\] Opening RocksDB handle: /var/osquery/osquery.db
osqueryd\[[0-9]*\]: .* [0-9]*:[0-9]*:[0-9]*\.[0-9]*\s*[0-9]* virtual_table.cpp:500\] The shell_history table returns data based on the current user by default, consider JOINing against the users table
osqueryd\[[0-9]*\]: .* [0-9]*:[0-9]*:[0-9]*\.[0-9]*\s*[0-9]* query.cpp:72\] Scheduled query has been updated: pack_.*
mount\[[0-9]*\]: mount: unknown filesystem type 'binfmt_misc'
systemd\[1\]: Failed to mount Arbitrary Executable File Formats File System.
systemd\[1\]: Mounting Arbitrary Executable File Formats File System...
systemd\[1\]: proc-sys-fs-binfmt_misc.automount: Got automount request for /proc/sys/fs/binfmt_misc, triggered by [0-9]* (osqueryd)
systemd\[1\]: proc-sys-fs-binfmt_misc.mount: Mount process exited, code=exited status=32
systemd\[1\]: proc-sys-fs-binfmt_misc.mount: Unit entered failed state.

## openvpn
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* TLS: soft reset sec=[0-9]* bytes=[0-9]*/[0-9]* pkts=[0-9]*/[0-9]*
ovpn-.*\[[0-9]*\]: TLS: soft reset sec=[0-9]* bytes=[0-9]*/[0-9]* pkts=[0-9]*/[0-9]*
ovpn-.*\[[0-9]*\]: Socket Buffers: R=\[[0-9]*->[0-9]*\] S=\[[0-9]*->[0-9]*\]
# client
ovpn-.*\[[0-9]*\]: VERIFY OK: depth=[0-9]*, C=[A-Z]{2}, ST=[A-Z]{2}, L=.*, O=.*, OU=.*, CN=.*, name=EasyRSA, emailAddress=.*
ovpn-.*\[[0-9]*\]: Data Channel Decrypt: Cipher 'AES-256-CBC' initialized with 256 bit key
ovpn-.*\[[0-9]*\]: Data Channel Decrypt: Using 512 bit message hash 'SHA512' for HMAC authentication
ovpn-.*\[[0-9]*\]: Data Channel Encrypt: Cipher 'AES-256-CBC' initialized with 256 bit key
ovpn-.*\[[0-9]*\]: Data Channel Encrypt: Using 512 bit message hash 'SHA512' for HMAC authentication
ovpn-.*\[[0-9]*\]: Control Channel: TLSv1, cipher TLSv1/SSLv3 DHE-RSA-AES256-GCM-SHA384, 2048 bit RSA
ovpn-.*\[[0-9]*\]: Control Channel: TLSv1, cipher TLSv1/SSLv3 DHE-RSA-AES256-SHA, 2048 bit RSA
# server
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* VERIFY OK: depth=[0-9]*, C=[A-Z]{2}, ST=[A-Z]{2}, L=.*, O=.*, OU=.*, CN=.*, name=EasyRSA, emailAddress=.*
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* Data Channel Decrypt: Cipher 'AES-256-CBC' initialized with 256 bit key
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* Data Channel Decrypt: Using 512 bit message hash 'SHA512' for HMAC authentication
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* Data Channel Encrypt: Cipher 'AES-256-CBC' initialized with 256 bit key
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* Data Channel Encrypt: Using 512 bit message hash 'SHA512' for HMAC authentication
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* Control Channel: TLSv1.2, cipher TLSv1/SSLv3 DHE-RSA-AES256-GCM-SHA384, 2048 bit RSA
ovpn-.*\[[0-9]*\]: .*/[0-9a-fA-F.:]*:[0-9]* Control Channel: TLSv1, cipher TLSv1/SSLv3 DHE-RSA-AES256-SHA, 2048 bit RSA
ovpn-.*\[[0-9]*\]: VERIFY OK: nsCertType=SERVER

## fail2ban
fail2ban.filter         \[[0-9]*\]: INFO    \[.*\] Found
fail2ban.filter         \[[0-9]*\]: INFO    Log rotation detected for /var/log/syslog
fail2ban.filter         \[[0-9]*\]: INFO    Log rotation detected for /var/log/auth.log
fail2ban.server         \[[0-9]*\]: INFO    rollover performed on /var/log/fail2ban.log

## iptables...
iptables denied: IN=

## supervisor
INFO supervisord started with pid [0-9]*
INFO waiting for .* to stop
INFO stopped: .* (terminated by SIGTERM)
INFO stopped: .* (exit status [0-9]*)
INFO exited: .* (exit status [0-9]*; expected)
INFO spawned: '.*' with pid [0-9]*
INFO success: .* entered RUNNING state, process has stayed up for > than [0-9]* seconds (startsecs)
WARN received SIGTERM indicating exit request
INFO waiting for .* to die
WARN Included extra file "/etc/supervisor/conf.d/.*.conf" during parsing

## ansible
ansible-async_wrapper(.py?): Module complete ([0-9]*)
ansible-async_wrapper(.py?): Done in kid B.
ansible-async_wrapper(.py?): Return async_wrapper task started.
ansible-async_wrapper(.py?): Starting module and watcher
ansible-async_wrapper(.py?): Start module ([0-9]*)
ansible-async_wrapper(.py?): Start watching [0-9]* ([0-9]*)

## livepatch
canonical-livepatch\[[0-9]*\]: Checking with livepatch service.
canonical-livepatch\[[0-9]*\]: No payload available.
canonical-livepatch\[[0-9]*\]: No updates available at this time.

## named
named\[[0-9]*\]: automatic empty zone: .*.IN-ADDR.ARPA

## falco
falco: Falco initialized with configuration file /etc/falco.yaml
falco: Parsed rules from file /etc/falco_rules.yaml

containerd: time=".*" level=info msg=

## nextcloud.logrotate snap and others
.*\.logrotate\[[0-9]*\]: Allocating hash table for state file, size [0-9]* entries
.*\.logrotate\[[0-9]*\]: Creating new state
.*\.logrotate\[[0-9]*\]: empty log files are not rotated, old logs are removed
.*\.logrotate\[[0-9]*\]: Handling [0-9]* logs
.*\.logrotate\[[0-9]*\]:   Last rotated at [0-9]*-[0-9]*-[0-9]* [0-9]*:[0-9]*
.*\.logrotate\[[0-9]*\]:   Now: [0-9]*-[0-9]*-[0-9]* [0-9]*:[0-9]*
.*\.logrotate\[[0-9]*\]:   log does not need rotating
.*\.logrotate\[[0-9]*\]:   log .* does not exist -- skipping
.*\.logrotate\[[0-9]*\]: message repeated [0-9]* times: \[ Creating new state\]
.*\.logrotate\[[0-9]*\]:  Now: [0-9]*-[0-9]*-[0-9]* [0-9]*:[0-9]*
.*\.logrotate\[[0-9]*\]: Reading state from file: \/var\/snap\/.*\/[0-9]*\/logrotate\/status
.*\.renew-certs\[[0-9]*\]: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
.*\.renew-certs\[[0-9]*\]: No hooks were run.
.*\.renew-certs\[[0-9]*\]: No renewals were attempted.
.*\.renew-certs\[[0-9]*\]: Saving debug log to \/var\/snap\/.*\/current\/certs\/certbot\/logs\/letsencrypt.log
